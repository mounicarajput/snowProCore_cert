101. Which of the following statements is true of Snowflake micro-partitioning?
A. Micro-partitioning has been known to introduce data skew
B. Micro-partitioning: requires a partitioning schema to be defined up front
C. Micro-partitioning is transparently completed using the ordering that occurs when the data is inserted/loaded
D. Micro-partitioning can be disabled within a Snowflake account

Ans. C

Snowflake's micro-partitioning is transparent to users and is completed automatically as data is 
inserted or loaded into tables. It leverages clustering keys to organize data within each micro-partition, 
enhancing query performance without the need for users to define partitioning schemas upfront.

102. True or False: Snowflake bills for a minimum of five minutes each time a Virtual Warehouse is started.
A. True
B. False

Ans: B

It bills for minimum 1 minute.

103. When scaling up Virtual Warehouses by increasing Virtual Warehouse t-shirt size, you are primarily scaling for improved:
A. Concurrency
B. Performance

Ans: B

104. As a best practice, clustering keys should only be defined on tables of which minimum size?
A. Multi-Kilobyte (KB) Range
B. Multi-Megabyte (MB) Range
C. Multi-Gigabyte (GB) Range
D. Multi-Terabyte (TB) Range

Ans: D

Considerations for Choosing Clustering for a Table
Whether you want faster response times or lower overall costs, 
clustering is best for a table that meets all of the following criteria:
The table contains a large number of micro-partitions. Typically, 
this means that the table contains multiple terabytes (TB) of data.

105. How a Snowpipe charges calculated?
A. Per-second/per Warehouse size
B. Per-second/per-core granularity
C. Number of Pipes in account
D. Total storage bucket size

Ans: B

Snowpipe’s serverless compute model, users can initiate any size load without managing a virtual warehouse

106. True or False: A Snowflake account is charged for data stored in both Internal and External Stages.
A. True
B. False

Ans: B

107. True or False: When active, a Pipe requires a dedicated Virtual Warehouse to execute.
A. True
B. False

Ans: B

108. True or False: Snowflake supports federated authentication in all editions.
A. True
B. False

Ans: A

Get the answer by searching federated authentication 
from https://docs.snowflake.com/en/user-guide/admin-security.html

109. True or False: When a new Snowflake object is created, it is automatically owned by the user who created it.
A. True
B. False

Ans: B

Any objects created after the command is issued are owned by the role in use when the object is created.
https://docs.snowflake.com/en/sql-reference/sql/grant-ownership#

110. True or False: A Virtual Warehouse consumes Snowflake credits even when inactive.
A. True
B. False

Ans:  A

111. True or False: During data unloading, only JSON and CSV files can be compressed.
A. True
B. False
Ans: B

During data loading, compression can be enabled for CSV, JSON PARQUET, AVRO, XML type files.
ref: https://docs.snowflake.com/en/sql-reference/sql/create-file-format

112.Which of the following are options when creating a Virtual Warehouse? (Choose two.)
A. Auto-suspend
B. Auto-resume
C. Local SSD size
D. User count

Ans: AB

113. Which formats are supported for unloading data from Snowflake? (Choose two.)
A. Delimited (CSV, TSV, etc.)
B. Avro
C. JSON
D. ORC
Ans: AC

Supported file formats
Delimited files (CSV, TSV, etc.)
JSON
Parquet

114. True or False: Data Providers can share data with only the Data Consumer.
A. True
B. False

Ans: False

115. The fail-safe retention period is how many days?
A. 1 day
B. 7 days
C. 45 days
D. 90 days

Ans: B

116. True or False: Once created, a micro-partition will never be changed.
A. True
B. False

Ans: A

117. What services does Snowflake automatically provide for customers that they may have been responsible for with their on-premise system? (Choose all that apply.)
A. Installing and configuring hardware
B. Patching software
C. Physical security
D. Maintaining metadata and statistics

Ans: BD

SNOWFLAKE is a true self-managed service, meaning:
• There is no hardware (virtual or physical) to select, install, configure, or manage.
• There is virtually no software to install, configure, or manage.
• Ongoing maintenance, management, upgrades, and tuning are handled by Snowflake.

118. Which of the following statements would be used to export/unload data from Snowflake?
A. COPY INTO @stage
B. EXPORT TO @stage
C. INSERT INTO @stage
D. EXPORT_TO_STAGE(stage => @stage, select => 'select * from t1');

Ans: A

119. True or False: A 4X-Large Warehouse may, at times, take longer to provision than a X-Small Warehouse.
A. True
B. False

Ans: A

Signed up for free Snowflake account. Created X-Small and 4X Virtual 
Warehouse using web interface. X-Small took 96 ms, while 4X took 105 ms. 
You can validate it in Activity -> Query History.

120. How would you determine the size of the virtual warehouse used for a task?
A. Root task may be executed concurrently (i.e. multiple instances), it is recommended to leave some margins in the execution window to avoid missing instances of execution
B. Querying (SELECT) the size of the stream content would help determine the warehouse size. For example, if querying large stream content, use a larger warehouse size
C. If using the stored procedure to execute multiple SQL statements, it's best to test run the stored procedure separately to size the compute resource first
D. Since task infrastructure is based on running the task body on schedule, it's recommended to configure the virtual warehouse for automatic concurrency handling using Multi-cluster warehouse (MCW) to match the task schedule

Ans: C

This option suggests that before executing the task, it's beneficial to 
test run the stored procedure separately to understand the compute resource requirements. 
This allows you to determine the appropriate size of the virtual warehouse needed to execute the task efficiently.

121. The Information Schema and Account Usage Share provide storage information for which of the following objects? (Choose three.)
A. Users
B. Tables
C. Databases
D. Internal Stages

Ans: BCD

122. What is the default File Format used in the COPY command if one is not specified?
A. CSV
B. JSON
C. Parquet
D. XML

Ans: A

123. True or False: Reader Accounts are able to extract data from shared data objects for use outside of Snowflake.
A. True
B. False

Ans: B (Re-check)

124. True or False: You can define multiple columns within a clustering key on a table.
A. True
B. False

Ans: A

125. True or False: Snowflake enforces unique, primary key, and foreign key constraints during DML operations.
A. True
B. False

Ans: B

126. True or False: Loading data into Snowflake requires that source data files be no larger than 16MB.
A. True
B. False

Ans: B

16 Mb is default. It can support till 5GB

127.True or False: A Virtual Warehouse can be resized while suspended.
A. True
B. False

Ans:A

128. True or False: When you create a custom role, it is a best practice to immediately grant that role to ACCOUNTADMIN.
A. True
B. False

Ans: B

129. Which of the following accurately represents how a table fits into Snowflake's logical container hierarchy?
A. Account -> Schema -> Database -> Table
B. Account -> Database -> Schema -> Table
C. Database -> Schema -> Table -> Account
D. Database -> Table -> Schema -> Account

Ans: B

130. True or False: All Snowflake table types include fail-safe storage.
A. True
B. False

Ans: A

All Snowflake table types, including permanent, temporary, and transient tables, 
include fail-safe storage. Fail-safe storage ensures that data is protected against 
hardware failures by automatically replicating data across multiple storage devices 
within the Snowflake system. This redundancy ensures high availability and durability 
of the data, regardless of the table type.

131.What are two ways to create and manage Data Shares in Snowflake? (Choose two.)
A. Via the Snowflake Web Interface (UI)
B. Via the DATA_SHARE=TRUE parameter
C. Via SQL commands
D. Via Virtual Warehouses

Ans: AC

132.True or False: Fail-safe can be disabled within a Snowflake account.
A. True
B. False

Ans: B

133. True or False: It is possible for a user to run a query against the query result cache without requiring an active Warehouse.
A. True
B. False

Ans: A

Query result cache is all about fetching the data from cloud services 
layer and saving the cost by not running the virtual warehouse.

134. True or False: When Snowflake is configured to use Single Sign-On (SSO), Snowflake receives the usernames and credentials from the SSO service and loads them into the customer's Snowflake account.
A. True
B. False

Ans: B

No. it does not save any credentials in an Account. Purpose of Federated and 
SSO is to authenticate the User and pass the authorization to SSO/Snowflake.

135. Which of the following are best practices for loading data into Snowflake? (Choose three.)
A. Aim to produce data files that are between 100 MB and 250 MB in size, compressed.
B. Load data from files in a cloud storage service in a different region or cloud platform from the service or region containing the Snowflake account, to save on cost.
C. Enclose fields that contain delimiter characters in single or double quotes.
D. Split large files into a greater number of smaller files to distribute the load among the compute resources in an active warehouse.
E. When planning which warehouse(s) to use for data loading, start with the largest warehouse possible.
F. Partition the staged data into large folders with random paths, allowing Snowflake to determine the best way to load each file.

Ans: ACD

136. Which Snowflake feature is used for both querying and restoring data?
A. Cluster keys
B. Time Travel
C. Fail-safe
D. Cloning

Ans: B
Querying, cloning, and restoring historical data in tables, schemas, and databases for up to 90 days through Snowflake Time Travel.

137. What do the terms scale up and scale out refer to in Snowflake? (Choose two.)
A. Scaling out adds clusters of the same size to a virtual warehouse to handle more concurrent queries.
B. Scaling out adds clusters of varying sizes to a virtual warehouse.
C. Scaling out adds additional database servers to an existing running cluster to handle more concurrent queries.
D. Snowflake recommends using both scaling up and scaling out to handle more concurrent queries.
E. Scaling up resizes a virtual warehouse so it can handle more complex workloads.
F. Scaling up adds additional database servers to an existing running cluster to handle larger workloads.

Ans: AE

Scaling out involves adding more clusters (or nodes) to a virtual warehouse to 
increase its capacity for handling concurrent queries. Scaling up, on the other hand, 
involves increasing the size or capacity of existing clusters within a virtual warehouse 
to handle more complex workloads or larger queries.

138. What is the minimum Snowflake edition that has column-level security enabled?
A. Standard
B. Enterprise
C. Business Critical
D. Virtual Private Snowflake

Ans: B

139. What parameter controls if the Virtual Warehouse starts immediately after the CREATE WAREHOUSE statement?
A. INITIALLY_SUSPENDED = TRUE/FALSE
B. START_AFTER_CREATE = TRUE/FALSE
C. START_THE = 60 // (seconds from now)
D. START_TIME = CURRENT_DATE()

Ans: A

140. When cloning a database, what is cloned with the database? (Choose two.)
A. Privileges on the database
B. Existing child objects within the database
C. Future child objects within the database
D. Privileges on the schemas within the database
E. Only schemas and tables within the database

Ans: BD

141. Which of the following describes the Snowflake Cloud Services layer?
A. Coordinates activities in the Snowflake account
B. Executes queries submitted by the Snowflake account users
C. Manages quotas on the Snowflake account storage
D. Manages the virtual warehouse cache to speed up queries

Ans: A

A. Coordinates activities in the Snowflake account - CLOUD SERVICE LAYER
B. Executes queries submitted by the Snowflake account users - COMPUTE LAYER
C. Manages quotas on the Snowflake account storage - STORAGE LAYER
D. Manages the virtual warehouse cache to speed up queries - COMPUTE LAYER


142. What is the maximum total Continuous Data Protection (CDP) charges incurred for a temporary table?
A. 30 days
B. 7 days
C. 48 hours
D. 24 hours
Ans: D

143. When reviewing a query profile, what is a symptom that a query is too large to fit into the memory?
A. A single join node uses more than 50% of the query time
B. Partitions scanned is equal to partitions total
C. An AggregateOperator node is present
D. The query is spilling to remote storage

Ans: D

144. What type of query benefits the MOST from search optimization?
A. A query that uses only disjunction (i.e., OR) predicates
B. A query that includes analytical expressions
C. A query that uses equality predicates or predicates that use IN
D. A query that filters on semi-structured data types

Ans: C

145. What transformations are supported in a CREATE PIPE ... AS COPY `¦ FROM (`¦) statement? (Choose two.)
A. Data can be filtered by an optional WHERE clause.
B. Incoming data can be joined with other tables.
C. Columns can be reordered.
D. Columns can be omitted.
E. Row level access can be defined.

Ans: CD

146. Which of the following are characteristics of Snowflake virtual warehouses? (Choose two.)
A. Auto-resume applies only to the last warehouse that was started in a multi-cluster warehouse.
B. The ability to auto-suspend a warehouse is only available in the Enterprise edition or above.
C. SnowSQL supports both a configuration file and a command line option for specifying a default warehouse.
D. A user cannot specify a default warehouse when using the ODBC driver.
E. The default virtual warehouse size can be changed at any time.
 
Ans: CE
147. Which command should be used to load data from a file, located in an external stage, into a table in Snowflake?
A. INSERT
B. PUT
C. GET
D. COPY
Ans: D

148. The Snowflake Cloud Data Platform is described as having which of the following architectures?
A. Shared-disk
B. Shared-nothing
C. Multi-cluster shared data
D. Serverless query engine
Ans: C

149. Which of the following is a data tokenization integration partner?
A. Protegrity
B. Tableau
C. DBeaver
D. SAP

Ans: A

The following partners facilitate external tokenization in Snowflake. 
To use these partner integrations, follow the instructions in the partner 
documentation or contact the partner to begin the configuration process:

ALTR
Baffle
Fortanix
MicroFocus CyberRes Voltage
Protegrity
Privacera
SecuPI
Skyflow

150.What versions of Snowflake should be used to manage compliance with Personal Identifiable Information (PII) requirements? (Choose two.)
A. Custom Edition
B. Virtual Private Snowflake
C. Business Critical Edition
D. Standard Edition
E. Enterprise Edition

Ans: BC

151.What are supported file formats for unloading data from Snowflake? (Choose three.)
A. XML
B. JSON
C. Parquet
D. ORC
E. AVRO
F. CSV
Ans: BCF

152. The Snowflake cloud services layer is responsible for which tasks? (Choose two.)
A. Local disk caching
B. Authentication and access control
C. Metadata management
D. Query processing
E. Database storage

Ans: BC
Services managed in this layer include:
Authentication
Infrastructure management
Metadata management
Query parsing and optimization
Access control

153. What is a key feature of Snowflake architecture?
A. Zero-copy cloning creates a mirror copy of a database that updates with the original.
B. Software updates are automatically applied on a quarterly basis.
C. Snowflake eliminates resource contention with its virtual warehouse implementation.
D. Multi-cluster warehouses allow users to run a query that spans across multiple clusters.
E. Snowflake automatically sorts DATE columns during ingest, for fast retrieval by date.

Ans: C

One of the key features of Snowflake architecture is its virtual warehouse implementation, which eliminates resource contention by enabling each query to execute in its own isolated compute environment. This ensures that queries do not compete for resources and can be executed independently, leading to improved performance and scalability.

154. When publishing a Snowflake Data Marketplace listing into a remote region what should be taken into consideration? (Choose two.)
A. There is no need to have a Snowflake account in the target region, a share will be created for each user.
B. The listing is replicated into all selected regions automatically, the data is not.
C. The user must have the ORGADMIN role available in at least one account to link accounts for replication.
D. Shares attached to listings in remote regions can be viewed from any account in an organization.
E. For a standard listing the user can wait until the first customer requests the data before replicating it to the target region.

Ans: BC (re-check)

155. When loading data into Snowflake via Snowpipe what is the compressed file size recommendation?
A. 10-50 MB
B. 100-250 MB
C. 300-500 MB
D. 1000-1500 MB

Ans: B

156. Which Snowflake feature allows a user to substitute a randomly generated identifier for sensitive data, in order to prevent unauthorized users access to the data, before loading it into Snowflake?
A. External Tokenization
B. External Tables
C. Materialized Views
D. User-Defined Table Functions (UDTF)

Ans: A

157: Which of the following are examples of operations that require a Virtual Warehouse to complete, assuming no queries have been executed previously? (Choose three.)
A. MIN(<< column value >>)
B. COPY
C. SUM(<< column value >>)
D. UPDATE

Ans: BCD

158.What is the SNOWFLAKE.ACCOUNT_USAGE view that contains information about which objects were read by queries within the last 365 days (1 year)?
A. VIEWS_HISTORY
B. OBJECT_HISTORY
C. ACCESS_HISTORY
D. LOGIN_HISTORY

Ans: C

159. Which feature is only available in the Enterprise or higher editions of Snowflake?
A. Column-level security
B. SOC 2 type II certification
C. Multi-factor Authentication (MFA)
D. Object-level access control

Ans: A

160. Will data cached in a warehouse be lost when the warehouse is resized?
A. Possibly, if the warehouse is resized to a smaller size and the cache no longer fits. Most Voted
B. Yes, because the compute resource is replaced in its entirety with a new compute resource.
C. No, because the size of the cache is independent from the warehouse size.
D. Yes, because the new compute resource will no longer have access to the cache encryption key.

Ans: A

161. Which semi-structured file formats are supported when unloading data from a table? (Choose two.)
A. ORC
B. XML
C. Avro
D. Parquet
E. JSON

Ans: DE

Structured: Delimited (CSV, TSV, etc.)
Semi-structured: JSON, Parquet

162. A running virtual warehouse is suspended.
What is the MINIMUM amount of time that the warehouse will incur charges for when it is restarted?
A. 1 second
B. 60 seconds
C. 5 minutes
D. 60 minutes

Ans: B

163. What are the responsibilities of Snowflake's Cloud Service layer? (Choose three.)
A. Authentication
B. Resource management
C. Virtual warehouse caching
D. Query parsing and optimization
E. Query execution
F. Physical storage of micro-partitions

Ans: ABD

164. How long is the Fail-safe period for temporary and transient tables?
A. There is no Fail-safe period for these tables.
B. 1 day
C. 7 days
D. 31 days
E. 90 days

Ans: A

165. Which command should be used to download files from a Snowflake stage to a local folder on a client's machine?
A. PUT
B. GET
C. COPY
D. SELECT

Ans: B

166. How does Snowflake Fail-safe protect data in a permanent table?
A. Fail-safe makes data available up to 1 day, recoverable by user operations.
B. Fail-safe makes data available for 7 days, recoverable by user operations.
C. Fail-safe makes data available for 7 days, recoverable only by Snowflake Support.
D. Fail-safe makes data available up to 1 day, recoverable only by Snowflake Support.

Ans: C

167.Which minimum Snowflake edition allows for a dedicated metadata store?
A. Standard
B. Enterprise
C. Business Critical
D. Virtual Private Snowflake

Ans: D

168. Network policies can be set at which Snowflake levels? (Choose two.)
A. Role
B. Schema
C. User
D. Database
E. Account
F. Tables

Ans: DE (re-check)

170. What are the correct parameters for time travel and fail-safe in the Snowflake Enterprise Edition?
A. Default Time Travel Retention is set to 0 days. Maximum Time Travel Retention is 30 days. Fail Safe retention time is 1 day.
B. Default Time Travel Retention is set to 1 day. Maximum Time Travel Retention is 365 days. Fail Safe retention time is 7 days.
C. Default Time Travel Retention is set to 0 days. Maximum Time Travel Retention is 90 days. Fail Safe retention time is 7 days.
D. Default Time Travel Retention is set to 1 day. Maximum Time Travel Retention is 90 days. Fail Safe retention time is 7 days.
E. Default Time Travel Retention is set to 7 days. Maximum Time Travel Retention is 1 day. Fail Safe retention time is 90 days.
F. Default Time Travel Retention is set to 90 days. Maximum Time Travel Retention is 7 days. Fail Safe retention time is 356 days.

Ans: D

171. Which of the following objects are contained within a schema? (Choose two.)
A. Role
B. Stream
C. Warehouse
D. External table
E. User
F. Share

Ans: BD

172. Which of the following statements describe features of Snowflake data caching? (Choose two.)
A. When a virtual warehouse is suspended, the data cache is saved on the remote storage layer.
B. When the data cache is full, the least-recently used data will be cleared to make room.
C. A user can only access their own queries from the query result cache.
D. A user must set USE_METADATA_CACHE to TRUE to use the metadata cache in queries.
E. The RESULT_SCAN table function can access and filter the contents of the query result cache.

Ans:  BD

173. A table needs to be loaded. The input data is in JSON format and is a concatenation of multiple JSON documents. The file size is 3 GB. A warehouse size S is being used. The following COPY INTO command was executed:
COPY INTO SAMPLE FROM @~/SAMPLE.JSON (TYPE=JSON)
The load failed with this error:
Max LOB size (16777216) exceeded, actual size of parsed column is 17894470.
How can this issue be resolved?
A. Compress the file and load the compressed file.
B. Split the file into multiple files in the recommended size range (100 MB - 250 MB).
C. Use a larger-sized warehouse.
D. Set STRIP_OUTER_ARRAY=TRUE in the COPY INTO command.

Ans: B

174. What is a feature of a stored procedure in Snowflake?
A. They can be created as secure and hide the underlying metadata from all users.
B. They can access tables from a single database.
C. They can only contain a single SQL statement.
D. They can be created to run with a caller's rights or an owner's rights.

Ans: D

175. Which columns are part of the result set of the Snowflake LATERAL FLATTEN command? (Choose two.)

A. CONTENT
B. PATH
C. BYTE_SIZE
D. INDEX
E. DATATYPE

Ans: BD

176. What is the minimum Snowflake edition required to create a materialized view?

A. Standard Edition
B. Enterprise Edition
C. Business Critical Edition
D. Virtual Private Snowflake Edition

Ans: B

177. Which Snowflake function will interpret an input string as a JSON document, and produce a VARIANT value?

A. parse_json()
B. json_extract_path_text()
C. object_construct()
D. flatten

Ans: A

178. How are serverless features billed?

A. Per second multiplied by an automatic sizing for the job
B. Per minute multiplied by an automatic sizing for the job, with a minimum of one minute
C. Per second multiplied by the size, as determined by the SERVERLESS_FEATURES_SIZE account parameter
D. Serverless features are not billed, unless the total cost for the month exceeds 10% of the warehouse credits, on the account
 
Ans: A
https://docs.snowflake.com/en/user-guide/cost-understanding-compute

179. Which Snowflake architectural layer is responsible for a query execution plan?

A. Compute
B. Data storage
C. Cloud services
D. Cloud provider

Ans: C

Notes: 

Cloud Provider Layer:

This layer is the underlying infrastructure provided by the chosen cloud provider (e.g., AWS, Azure, or GCP).
Responsibilities include provisioning and managing the physical hardware, networking, and data centers.

Data Storage Layer:

This layer is responsible for storing all data in Snowflake.
Snowflake uses a proprietary architecture called the "Multi-cluster, Shared Data Architecture" (MCSA).
Data is stored in a columnar format, compressed and encrypted by default.
Responsibilities include managing data storage, compression, encryption, and data durability.

Compute Layer:

This layer handles all computational tasks in Snowflake, such as query execution, data loading, and data transformation.
Snowflake automatically provisions and manages compute resources (virtual warehouses) based on workload demands.
Compute resources are separated from storage, allowing for independent scaling.
Responsibilities include query optimization, query execution, and processing of data operations.

Cloud Services Layer:

This layer is the brain of Snowflake, providing various services for managing and orchestrating the Snowflake environment.
It includes components such as the metadata service, query optimizer, transaction manager, session management, access control, and authentication.
The query optimizer generates efficient query execution plans, optimizing performance based on the data and workload characteristics.
Responsibilities include managing metadata, optimizing queries, coordinating transactions, and enforcing security policies.

Client Layer:

This layer consists of client applications and tools that interact with Snowflake.
Examples include SQL clients, BI tools, ETL tools, and custom applications.
Responsibilities include sending queries, receiving results, monitoring, and managing the Snowflake environment.


180.When unloading to a stage, which of the following is a recommended practice or approach?

A. Set SINGLE = TRUE for larger files.
B. Use OBJECT_CONSTRUCT(*) when using Parquet.
C. Avoid the use of the CAST function.
D. Define an individual file format.

Ans: D

181. Which SQL commands, when committed, will consume a stream and advance the stream offset? (Choose two.)

A. UPDATE TABLE FROM STREAM
B. SELECT FROM STREAM
C. INSERT INTO TABLE SELECT FROM STREAM
D. ALTER TABLE AS SELECT FROM STREAM
E. BEGIN COMMIT

Ans: AC

182. Which methods can be used to delete staged files from a Snowflake stage? (Choose two.)

A. Use the DROP command after the load completes.
B. Specify the TEMPORARY option when creating the file format.
C. Specify the PURGE copy option in the COPY INTO command.
D. Use the REMOVE command after the load completes.
E. Use the DELETE LOAD HISTORY command after the load completes.

Ans: CD

183.On which of the following cloud platforms can a Snowflake account be hosted? (Choose three.)

A. Amazon Web Services
B. Private Virtual Cloud
C. Oracle Cloud
D. Microsoft Azure Cloud
E. Google Cloud Platform
F. Alibaba Cloud

Ans: ADE

184. What Snowflake role must be granted for a user to create and manage accounts?

A. ACCOUNTADMIN
B. ORGADMIN
C. SECURITYADMIN
D. SYSADMIN

Ans: B 

https://docs.snowflake.com/en/user-guide/organizations-manage-accounts
https://docs.snowflake.com/en/user-guide/security-access-control-considerations

185. Assume there is a table consisting of five micro-partitions with values ranging from A to Z.

Ans: A ( A - D , e-j , K - l..so on)

186.What feature can be used to reorganize a very large table on one or more columns?

A. Micro-partitions
B. Clustering keys
C. Key partitions
D. Clustered partitions

Ans: B

Clustering keys allow you to physically organize data within micro-partitions 
based on one or more columns. By defining clustering keys on a table, you can 
improve query performance, reduce query latency, and optimize storage efficiency
by grouping related data together. This reorganization helps in achieving better 
data locality and reduces the amount of data that needs to be scanned for queries involving the specified columns.

187.What is an advantage of using an explain plan instead of the query profiler to evaluate the performance of a query?

A. The explain plan output is available graphically.
B. An explain plan can be used to conduct performance analysis without executing a query.
C. An explain plan will handle queries with temporary tables and the query profiler will not.
D. An explain plan's output will display automatic data skew optimization information.
 
Ans: B

188. Which data types are supported by Snowflake when using semi-structured data? (Choose two.)

A. VARIANT
B. VARRAY
C. STRUCT
D. ARRAY
E. QUEUE

Ans: AD

189. Why does Snowflake recommend file sizes of 100-250 MB compressed when loading data?

A. Optimizes the virtual warehouse size and multi-cluster setting to economy mode
B. Allows a user to import the files in a sequential order
C. Increases the latency staging and accuracy when loading the data
D. Allows optimization of parallel operations

Ans: D

190. Which of the following features are available with the Snowflake Enterprise edition? (Choose two.)

A. Database replication and failover
B. Automated index management
C. Customer managed keys (Tri-secret secure)
D. Extended time travel
E. Native support for geospatial data

Ans: AD
